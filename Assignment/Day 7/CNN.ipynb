{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2lCl32_Um_Xu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models, callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1,28,28,1).astype('float32') / 255.0\n",
        "x_test  = x_test.reshape(-1,28,28,1).astype('float32') / 255.0\n",
        "\n",
        "y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test_oh  = tf.keras.utils.to_categorical(y_test,  num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrTaGqcsnMzY",
        "outputId": "571018ab-b165-4cf8-81f8-29e1086cf0e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn():\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WpUc0X7ynWt3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
        "lr_schedule1 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "lr_schedule2 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.01 * 0.95**epoch, verbose=1)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.15)\n",
        "\n",
        "\n",
        "model = build_cnn()\n",
        "model.compile(optimizer=optimizer, loss=loss_fn , metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train_oh, epochs=50, batch_size=256, validation_split=0.1, callbacks=[lr_schedule2, early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ABdXBYna4T",
        "outputId": "a38f1e40-7d3f-487d-e0b8-58ac461047c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 507ms/step - accuracy: 0.8449 - loss: 1.1922 - val_accuracy: 0.1372 - val_loss: 2.2608 - learning_rate: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0095.\n",
            "Epoch 2/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 499ms/step - accuracy: 0.9800 - loss: 0.8189 - val_accuracy: 0.9403 - val_loss: 1.0470 - learning_rate: 0.0095\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009025.\n",
            "Epoch 3/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 511ms/step - accuracy: 0.9855 - loss: 0.7952 - val_accuracy: 0.9892 - val_loss: 0.7596 - learning_rate: 0.0090\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00857375.\n",
            "Epoch 4/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 501ms/step - accuracy: 0.9884 - loss: 0.7847 - val_accuracy: 0.9915 - val_loss: 0.7423 - learning_rate: 0.0086\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0081450625.\n",
            "Epoch 5/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 496ms/step - accuracy: 0.9907 - loss: 0.7754 - val_accuracy: 0.9933 - val_loss: 0.7374 - learning_rate: 0.0081\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.007737809374999998.\n",
            "Epoch 6/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 506ms/step - accuracy: 0.9912 - loss: 0.7710 - val_accuracy: 0.9927 - val_loss: 0.7372 - learning_rate: 0.0077\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.007350918906249998.\n",
            "Epoch 7/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 494ms/step - accuracy: 0.9927 - loss: 0.7671 - val_accuracy: 0.9925 - val_loss: 0.7337 - learning_rate: 0.0074\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.006983372960937498.\n",
            "Epoch 8/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 497ms/step - accuracy: 0.9922 - loss: 0.7657 - val_accuracy: 0.9927 - val_loss: 0.7318 - learning_rate: 0.0070\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.006634204312890623.\n",
            "Epoch 9/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 494ms/step - accuracy: 0.9934 - loss: 0.7615 - val_accuracy: 0.9920 - val_loss: 0.7326 - learning_rate: 0.0066\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.006302494097246091.\n",
            "Epoch 10/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 501ms/step - accuracy: 0.9942 - loss: 0.7600 - val_accuracy: 0.9927 - val_loss: 0.7295 - learning_rate: 0.0063\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.005987369392383787.\n",
            "Epoch 11/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 502ms/step - accuracy: 0.9941 - loss: 0.7581 - val_accuracy: 0.9940 - val_loss: 0.7286 - learning_rate: 0.0060\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.005688000922764597.\n",
            "Epoch 12/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 499ms/step - accuracy: 0.9949 - loss: 0.7558 - val_accuracy: 0.9933 - val_loss: 0.7293 - learning_rate: 0.0057\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.005403600876626367.\n",
            "Epoch 13/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 505ms/step - accuracy: 0.9950 - loss: 0.7552 - val_accuracy: 0.9930 - val_loss: 0.7286 - learning_rate: 0.0054\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.005133420832795048.\n",
            "Epoch 14/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 501ms/step - accuracy: 0.9950 - loss: 0.7535 - val_accuracy: 0.9933 - val_loss: 0.7273 - learning_rate: 0.0051\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0048767497911552955.\n",
            "Epoch 15/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 501ms/step - accuracy: 0.9954 - loss: 0.7521 - val_accuracy: 0.9927 - val_loss: 0.7265 - learning_rate: 0.0049\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.00463291230159753.\n",
            "Epoch 16/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 502ms/step - accuracy: 0.9957 - loss: 0.7506 - val_accuracy: 0.9938 - val_loss: 0.7260 - learning_rate: 0.0046\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0044012666865176535.\n",
            "Epoch 17/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 501ms/step - accuracy: 0.9955 - loss: 0.7511 - val_accuracy: 0.9928 - val_loss: 0.7265 - learning_rate: 0.0044\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.004181203352191771.\n",
            "Epoch 18/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 498ms/step - accuracy: 0.9957 - loss: 0.7495 - val_accuracy: 0.9932 - val_loss: 0.7254 - learning_rate: 0.0042\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.003972143184582182.\n",
            "Epoch 19/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 496ms/step - accuracy: 0.9961 - loss: 0.7493 - val_accuracy: 0.9930 - val_loss: 0.7248 - learning_rate: 0.0040\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0037735360253530726.\n",
            "Epoch 20/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 492ms/step - accuracy: 0.9963 - loss: 0.7490 - val_accuracy: 0.9932 - val_loss: 0.7246 - learning_rate: 0.0038\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0035848592240854188.\n",
            "Epoch 21/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 495ms/step - accuracy: 0.9972 - loss: 0.7473 - val_accuracy: 0.9938 - val_loss: 0.7247 - learning_rate: 0.0036\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.003405616262881148.\n",
            "Epoch 22/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 497ms/step - accuracy: 0.9964 - loss: 0.7473 - val_accuracy: 0.9932 - val_loss: 0.7238 - learning_rate: 0.0034\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0032353354497370902.\n",
            "Epoch 23/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 493ms/step - accuracy: 0.9969 - loss: 0.7469 - val_accuracy: 0.9933 - val_loss: 0.7238 - learning_rate: 0.0032\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.003073568677250236.\n",
            "Epoch 24/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 506ms/step - accuracy: 0.9969 - loss: 0.7458 - val_accuracy: 0.9930 - val_loss: 0.7237 - learning_rate: 0.0031\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.002919890243387724.\n",
            "Epoch 25/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 495ms/step - accuracy: 0.9967 - loss: 0.7451 - val_accuracy: 0.9933 - val_loss: 0.7235 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.002773895731218338.\n",
            "Epoch 26/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 489ms/step - accuracy: 0.9968 - loss: 0.7456 - val_accuracy: 0.9937 - val_loss: 0.7231 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0026352009446574203.\n",
            "Epoch 27/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 504ms/step - accuracy: 0.9973 - loss: 0.7455 - val_accuracy: 0.9928 - val_loss: 0.7233 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.002503440897424549.\n",
            "Epoch 28/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 488ms/step - accuracy: 0.9973 - loss: 0.7443 - val_accuracy: 0.9935 - val_loss: 0.7232 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0023782688525533216.\n",
            "Epoch 29/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 504ms/step - accuracy: 0.9978 - loss: 0.7433 - val_accuracy: 0.9933 - val_loss: 0.7232 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0022593554099256557.\n",
            "Epoch 30/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 497ms/step - accuracy: 0.9975 - loss: 0.7445 - val_accuracy: 0.9935 - val_loss: 0.7225 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0021463876394293728.\n",
            "Epoch 31/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 493ms/step - accuracy: 0.9974 - loss: 0.7437 - val_accuracy: 0.9938 - val_loss: 0.7223 - learning_rate: 0.0021\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0020390682574579037.\n",
            "Epoch 32/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 492ms/step - accuracy: 0.9975 - loss: 0.7439 - val_accuracy: 0.9933 - val_loss: 0.7225 - learning_rate: 0.0020\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0019371148445850087.\n",
            "Epoch 33/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 500ms/step - accuracy: 0.9974 - loss: 0.7427 - val_accuracy: 0.9933 - val_loss: 0.7222 - learning_rate: 0.0019\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0018402591023557583.\n",
            "Epoch 34/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 493ms/step - accuracy: 0.9975 - loss: 0.7422 - val_accuracy: 0.9935 - val_loss: 0.7222 - learning_rate: 0.0018\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0017482461472379703.\n",
            "Epoch 35/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 511ms/step - accuracy: 0.9979 - loss: 0.7428 - val_accuracy: 0.9935 - val_loss: 0.7221 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0016608338398760717.\n",
            "Epoch 36/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 503ms/step - accuracy: 0.9975 - loss: 0.7422 - val_accuracy: 0.9935 - val_loss: 0.7221 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.001577792147882268.\n",
            "Epoch 37/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 499ms/step - accuracy: 0.9978 - loss: 0.7422 - val_accuracy: 0.9937 - val_loss: 0.7221 - learning_rate: 0.0016\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0014989025404881545.\n",
            "Epoch 38/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 498ms/step - accuracy: 0.9981 - loss: 0.7415 - val_accuracy: 0.9932 - val_loss: 0.7219 - learning_rate: 0.0015\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0014239574134637467.\n",
            "Epoch 39/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 488ms/step - accuracy: 0.9976 - loss: 0.7417 - val_accuracy: 0.9933 - val_loss: 0.7220 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0013527595427905593.\n",
            "Epoch 40/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 489ms/step - accuracy: 0.9978 - loss: 0.7412 - val_accuracy: 0.9933 - val_loss: 0.7218 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0012851215656510312.\n",
            "Epoch 41/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 500ms/step - accuracy: 0.9979 - loss: 0.7412 - val_accuracy: 0.9932 - val_loss: 0.7220 - learning_rate: 0.0013\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0012208654873684796.\n",
            "Epoch 42/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 494ms/step - accuracy: 0.9978 - loss: 0.7418 - val_accuracy: 0.9933 - val_loss: 0.7219 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.0011598222130000556.\n",
            "Epoch 43/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 489ms/step - accuracy: 0.9981 - loss: 0.7418 - val_accuracy: 0.9933 - val_loss: 0.7219 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.0011018311023500529.\n",
            "Epoch 44/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 500ms/step - accuracy: 0.9980 - loss: 0.7409 - val_accuracy: 0.9935 - val_loss: 0.7217 - learning_rate: 0.0011\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0010467395472325502.\n",
            "Epoch 45/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 494ms/step - accuracy: 0.9977 - loss: 0.7408 - val_accuracy: 0.9933 - val_loss: 0.7216 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0009944025698709225.\n",
            "Epoch 46/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 493ms/step - accuracy: 0.9978 - loss: 0.7412 - val_accuracy: 0.9933 - val_loss: 0.7217 - learning_rate: 9.9440e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0009446824413773763.\n",
            "Epoch 47/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 488ms/step - accuracy: 0.9976 - loss: 0.7411 - val_accuracy: 0.9937 - val_loss: 0.7215 - learning_rate: 9.4468e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0008974483193085076.\n",
            "Epoch 48/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 488ms/step - accuracy: 0.9984 - loss: 0.7408 - val_accuracy: 0.9932 - val_loss: 0.7213 - learning_rate: 8.9745e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.000852575903343082.\n",
            "Epoch 49/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 490ms/step - accuracy: 0.9982 - loss: 0.7408 - val_accuracy: 0.9933 - val_loss: 0.7216 - learning_rate: 8.5258e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.000809947108175928.\n",
            "Epoch 50/50\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 503ms/step - accuracy: 0.9980 - loss: 0.7405 - val_accuracy: 0.9935 - val_loss: 0.7215 - learning_rate: 8.0995e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79e2ee527790>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test_oh)\n",
        "print(f\"Test accuracy: {test_acc*100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QEaio_enkIO",
        "outputId": "dcff4784-03fb-45b5-a413-9864ab09926f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9915 - loss: 0.7293\n",
            "Test accuracy: 99.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7I7aWeKA-W5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}